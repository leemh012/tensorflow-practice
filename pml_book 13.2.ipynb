{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b) + c => 1\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)\n",
    "\n",
    "z = 2*(a-b) + c\n",
    "\n",
    "print('2*(a-b) + c =>', z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b) + c => 1\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    print('2*(a-b) + c =>', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=AddV2>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"AddV2\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 175\n",
       "}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b) + c => 1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_func():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "print('2*(a-b) + c =>', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b) + c => 1\n"
     ]
    }
   ],
   "source": [
    "def simple_func():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "simple_func = tf.function(simple_func)\n",
    "print('2*(a-b) + c =>', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func = simple_func.get_concrete_function()\n",
    "con_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w1:0' shape=(2, 4) dtype=int64>\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                               [5, 6, 7, 8]]), name='w1')\n",
    "\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'w1/Initializer/initial_value' type=Const>,\n",
       " <tf.Operation 'w1' type=VarHandleOp>,\n",
       " <tf.Operation 'w1/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'w1/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'w1/Read/ReadVariableOp' type=ReadVariableOp>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^w1/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    print(init.node_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2, 4), dtype=int64)\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    w1 = w1 + 1\n",
    "    print(w1)\n",
    "    \n",
    "with tf.compat.v1.Session(graph=g1) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                               [5, 6, 7, 8]]), name='w1')\n",
    "    w1 = w1.assign(w1 + 1)\n",
    "\n",
    "with tf.compat.v1.Session(graph=g2) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "w2 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                           [5, 6, 7, 8]]), name='w2')\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]], shape=(2, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(w2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())\n",
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[ 3,  4,  5,  6],\n",
      "       [ 7,  8,  9, 10]])>\n"
     ]
    }
   ],
   "source": [
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ramdom_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    \n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0,\n",
    "                             scale=(0.5 + t*t/3))\n",
    "        y.append(r)\n",
    "    return x, 1.726*x - 0.84 + np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = make_ramdom_data()\n",
    "\n",
    "plt.plot(x,y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105 [==============================] - 0s 2ms/sample - loss: 3.5843 - val_loss: 2.2386\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 3.0694 - val_loss: 1.9603\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 2.5965 - val_loss: 1.7557\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 2.2480 - val_loss: 1.5780\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 1.9482 - val_loss: 1.4427\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 1.7186 - val_loss: 1.3374\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 1.5495 - val_loss: 1.2652\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 1.4210 - val_loss: 1.1954\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 156us/sample - loss: 1.2937 - val_loss: 1.1233\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 1.1759 - val_loss: 1.0673\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 1.0871 - val_loss: 1.0335\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 1.0239 - val_loss: 1.0101\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.9788 - val_loss: 0.9863\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.9392 - val_loss: 0.9702\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 157us/sample - loss: 0.9109 - val_loss: 0.9501\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.8797 - val_loss: 0.9421\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.8584 - val_loss: 0.9299\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.8399 - val_loss: 0.9250\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.8273 - val_loss: 0.9167\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.8126 - val_loss: 0.9133\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.8017 - val_loss: 0.9055\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7929 - val_loss: 0.9064\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7914 - val_loss: 0.9005\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7835 - val_loss: 0.9037\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7813 - val_loss: 0.9000\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7758 - val_loss: 0.9028\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7732 - val_loss: 0.8967\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 159us/sample - loss: 0.7691 - val_loss: 0.8945\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7677 - val_loss: 0.8929\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7653 - val_loss: 0.8939\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7644 - val_loss: 0.8953\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7620 - val_loss: 0.8969\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 158us/sample - loss: 0.7609 - val_loss: 0.8950\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7608 - val_loss: 0.8980\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7607 - val_loss: 0.8944\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7606 - val_loss: 0.8953\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7593 - val_loss: 0.8947\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7582 - val_loss: 0.8950\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.7606 - val_loss: 0.8906\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7577 - val_loss: 0.8911\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7577 - val_loss: 0.8925\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7577 - val_loss: 0.8941\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7569 - val_loss: 0.8943\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7572 - val_loss: 0.8941\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7569 - val_loss: 0.8946\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7574 - val_loss: 0.8951\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7567 - val_loss: 0.8934\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 159us/sample - loss: 0.7569 - val_loss: 0.8983\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7561 - val_loss: 0.8955\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7567 - val_loss: 0.8948\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.7565 - val_loss: 0.8936\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 158us/sample - loss: 0.7569 - val_loss: 0.8953\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7567 - val_loss: 0.8997\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 161us/sample - loss: 0.7565 - val_loss: 0.9041\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7564 - val_loss: 0.9015\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7582 - val_loss: 0.9003\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7570 - val_loss: 0.9030\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7565 - val_loss: 0.9026\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7576 - val_loss: 0.9038\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7560 - val_loss: 0.9038\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7585 - val_loss: 0.9059\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7572 - val_loss: 0.9021\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7565 - val_loss: 0.9010\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7558 - val_loss: 0.9018\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7561 - val_loss: 0.9007\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7563 - val_loss: 0.8984\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7570 - val_loss: 0.9004\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7569 - val_loss: 0.8990\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7560 - val_loss: 0.8980\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7574 - val_loss: 0.8936\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.460 - 0s 141us/sample - loss: 0.7577 - val_loss: 0.8918\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7589 - val_loss: 0.8915\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7575 - val_loss: 0.8924\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7586 - val_loss: 0.8922\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7584 - val_loss: 0.8945\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7573 - val_loss: 0.8944\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 158us/sample - loss: 0.7576 - val_loss: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7578 - val_loss: 0.8962\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7577 - val_loss: 0.8958\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7598 - val_loss: 0.8968\n",
      "Epoch 81/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7580 - val_loss: 0.8961\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7568 - val_loss: 0.8958\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7568 - val_loss: 0.8963\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7585 - val_loss: 0.8963\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7571 - val_loss: 0.8960\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7578 - val_loss: 0.8956\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7577 - val_loss: 0.8959\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7579 - val_loss: 0.8998\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7569 - val_loss: 0.9047\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7570 - val_loss: 0.9050\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7578 - val_loss: 0.9033\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7562 - val_loss: 0.9027\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7559 - val_loss: 0.9016\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 156us/sample - loss: 0.7576 - val_loss: 0.9011\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7560 - val_loss: 0.9005\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7566 - val_loss: 0.9039\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7561 - val_loss: 0.9033\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7564 - val_loss: 0.9026\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7564 - val_loss: 0.8977\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7564 - val_loss: 0.9003\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7566 - val_loss: 0.9028\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7558 - val_loss: 0.9035\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7565 - val_loss: 0.9018\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7572 - val_loss: 0.9004\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 1.116 - 0s 151us/sample - loss: 0.7573 - val_loss: 0.9003\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7563 - val_loss: 0.9005\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 159us/sample - loss: 0.7576 - val_loss: 0.9002\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7579 - val_loss: 0.9051\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7571 - val_loss: 0.9031\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7569 - val_loss: 0.9026\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7567 - val_loss: 0.9039\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7580 - val_loss: 0.9036\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7561 - val_loss: 0.9020\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7563 - val_loss: 0.9006\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7577 - val_loss: 0.8990\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7566 - val_loss: 0.9001\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7577 - val_loss: 0.9004\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7559 - val_loss: 0.9044\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7562 - val_loss: 0.9089\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7558 - val_loss: 0.9099\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 159us/sample - loss: 0.7581 - val_loss: 0.9128\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7583 - val_loss: 0.9113\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7566 - val_loss: 0.9090\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7564 - val_loss: 0.9040\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 164us/sample - loss: 0.7558 - val_loss: 0.9041\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7566 - val_loss: 0.9013\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.7571 - val_loss: 0.9008\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7560 - val_loss: 0.8999\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7564 - val_loss: 0.9002\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7572 - val_loss: 0.9003\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7561 - val_loss: 0.8997\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7564 - val_loss: 0.9001\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7565 - val_loss: 0.8991\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7563 - val_loss: 0.8969\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7564 - val_loss: 0.8993\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7572 - val_loss: 0.9002\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7565 - val_loss: 0.8962\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7568 - val_loss: 0.8981\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7561 - val_loss: 0.8986\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7562 - val_loss: 0.8958\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7569 - val_loss: 0.8933\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7563 - val_loss: 0.8946\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7581 - val_loss: 0.8935\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7570 - val_loss: 0.8942\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7560 - val_loss: 0.8965\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7567 - val_loss: 0.8954\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7570 - val_loss: 0.8969\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7560 - val_loss: 0.8975\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7563 - val_loss: 0.8983\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7568 - val_loss: 0.8963\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7566 - val_loss: 0.9016\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7567 - val_loss: 0.8989\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7566 - val_loss: 0.8996\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 157us/sample - loss: 0.7565 - val_loss: 0.8979\n",
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7562 - val_loss: 0.8972\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 158us/sample - loss: 0.7572 - val_loss: 0.8956\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7563 - val_loss: 0.8966\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7563 - val_loss: 0.9002\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7566 - val_loss: 0.9001\n",
      "Epoch 160/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7579 - val_loss: 0.9047\n",
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7568 - val_loss: 0.9020\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7578 - val_loss: 0.9030\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7571 - val_loss: 0.9027\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7570 - val_loss: 0.9037\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7563 - val_loss: 0.9051\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7567 - val_loss: 0.9018\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7562 - val_loss: 0.9045\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7569 - val_loss: 0.9011\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7563 - val_loss: 0.8998\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7559 - val_loss: 0.9023\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7575 - val_loss: 0.9055\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7565 - val_loss: 0.9114\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7565 - val_loss: 0.9070\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7562 - val_loss: 0.9093\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.9083\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7560 - val_loss: 0.9077\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7566 - val_loss: 0.9141\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7561 - val_loss: 0.9163\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7576 - val_loss: 0.9208\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7577 - val_loss: 0.9173\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7572 - val_loss: 0.9157\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7571 - val_loss: 0.9212\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7573 - val_loss: 0.9230\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7578 - val_loss: 0.9175\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7572 - val_loss: 0.9178\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7577 - val_loss: 0.9132\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7567 - val_loss: 0.9140\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7564 - val_loss: 0.9168\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.9226\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7570 - val_loss: 0.9235\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7573 - val_loss: 0.9228\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7582 - val_loss: 0.9175\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7579 - val_loss: 0.9147\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7585 - val_loss: 0.9148\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7563 - val_loss: 0.9139\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7567 - val_loss: 0.9154\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7564 - val_loss: 0.9143\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7565 - val_loss: 0.9149\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7582 - val_loss: 0.9147\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7562 - val_loss: 0.9149\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7575 - val_loss: 0.9098\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.7565 - val_loss: 0.9070\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7564 - val_loss: 0.9074\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7582 - val_loss: 0.9054\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7564 - val_loss: 0.9022\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7572 - val_loss: 0.9042\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7569 - val_loss: 0.9064\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7564 - val_loss: 0.9070\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7569 - val_loss: 0.9090\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7563 - val_loss: 0.9099\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7565 - val_loss: 0.9119\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7581 - val_loss: 0.9098\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7566 - val_loss: 0.9126\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7571 - val_loss: 0.9123\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7581 - val_loss: 0.9094\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.9054\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7569 - val_loss: 0.9038\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7562 - val_loss: 0.9050\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7566 - val_loss: 0.9021\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7559 - val_loss: 0.8997\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7557 - val_loss: 0.9011\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7576 - val_loss: 0.8997\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7569 - val_loss: 0.8959\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7571 - val_loss: 0.8980\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7583 - val_loss: 0.8984\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7565 - val_loss: 0.8979\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7563 - val_loss: 0.8975\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7563 - val_loss: 0.8961\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7564 - val_loss: 0.8980\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7566 - val_loss: 0.8992\n",
      "Epoch 231/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7561 - val_loss: 0.9010\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7563 - val_loss: 0.9009\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7556 - val_loss: 0.9003\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7572 - val_loss: 0.9007\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7568 - val_loss: 0.8994\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 235us/sample - loss: 0.7567 - val_loss: 0.8951\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7567 - val_loss: 0.8958\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7578 - val_loss: 0.8950\n",
      "Epoch 239/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7566 - val_loss: 0.8940\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7584 - val_loss: 0.8966\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7562 - val_loss: 0.8973\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7559 - val_loss: 0.8990\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.9008\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7559 - val_loss: 0.9008\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7560 - val_loss: 0.8989\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7560 - val_loss: 0.9000\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7563 - val_loss: 0.8968\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.8985\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7575 - val_loss: 0.9059\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7568 - val_loss: 0.9064\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7566 - val_loss: 0.9075\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7572 - val_loss: 0.9088\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7572 - val_loss: 0.9050\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7564 - val_loss: 0.9040\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7560 - val_loss: 0.9038\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7560 - val_loss: 0.9022\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7569 - val_loss: 0.9033\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7561 - val_loss: 0.9023\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7567 - val_loss: 0.8993\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7568 - val_loss: 0.9019\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7559 - val_loss: 0.9037\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7560 - val_loss: 0.9017\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7568 - val_loss: 0.9004\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7567 - val_loss: 0.9002\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7566 - val_loss: 0.9072\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7564 - val_loss: 0.9071\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7563 - val_loss: 0.9093\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7560 - val_loss: 0.9078\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7561 - val_loss: 0.9093\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.7559 - val_loss: 0.9075\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7557 - val_loss: 0.9063\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7564 - val_loss: 0.9044\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7556 - val_loss: 0.9036\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7561 - val_loss: 0.9022\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7569 - val_loss: 0.9030\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7568 - val_loss: 0.9038\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7570 - val_loss: 0.9057\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7564 - val_loss: 0.9059\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7563 - val_loss: 0.9021\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7572 - val_loss: 0.9047\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7559 - val_loss: 0.9044\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7561 - val_loss: 0.9063\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7563 - val_loss: 0.9062\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7572 - val_loss: 0.9082\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7561 - val_loss: 0.9098\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7562 - val_loss: 0.9089\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7558 - val_loss: 0.9112\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7561 - val_loss: 0.9100\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7558 - val_loss: 0.9105\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7581 - val_loss: 0.9133\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7565 - val_loss: 0.9133\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7574 - val_loss: 0.9111\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7573 - val_loss: 0.9101\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7563 - val_loss: 0.9146\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7564 - val_loss: 0.9112\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7568 - val_loss: 0.9094\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7567 - val_loss: 0.9092\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7561 - val_loss: 0.9066\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7575 - val_loss: 0.9080\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7579 - val_loss: 0.9043\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7562 - val_loss: 0.9041\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7559 - val_loss: 0.9074\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7560 - val_loss: 0.9111\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7571 - val_loss: 0.9208\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7587 - val_loss: 0.9186\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7562 - val_loss: 0.9175\n",
      "Epoch 307/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7581 - val_loss: 0.9147\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7565 - val_loss: 0.9138\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7564 - val_loss: 0.9100\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7577 - val_loss: 0.9089\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7563 - val_loss: 0.9098\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7575 - val_loss: 0.9065\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7562 - val_loss: 0.9105\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7564 - val_loss: 0.9093\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7565 - val_loss: 0.9076\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7566 - val_loss: 0.9069\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7571 - val_loss: 0.9032\n",
      "Epoch 318/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7562 - val_loss: 0.9033\n",
      "Epoch 319/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7560 - val_loss: 0.9042\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7560 - val_loss: 0.9040\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7556 - val_loss: 0.9040\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7557 - val_loss: 0.9048\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 230us/sample - loss: 0.7561 - val_loss: 0.9031\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7558 - val_loss: 0.9030\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7567 - val_loss: 0.9004\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7563 - val_loss: 0.8974\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7570 - val_loss: 0.8954\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7567 - val_loss: 0.8965\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7568 - val_loss: 0.9000\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7565 - val_loss: 0.8988\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7561 - val_loss: 0.9013\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7566 - val_loss: 0.8973\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7577 - val_loss: 0.8970\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7563 - val_loss: 0.8962\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7576 - val_loss: 0.8957\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 284us/sample - loss: 0.7567 - val_loss: 0.8995\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7564 - val_loss: 0.9013\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7563 - val_loss: 0.9018\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7561 - val_loss: 0.8991\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7565 - val_loss: 0.8969\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7564 - val_loss: 0.8943\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7572 - val_loss: 0.8964\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7567 - val_loss: 0.8972\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7580 - val_loss: 0.9025\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7564 - val_loss: 0.9046\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7560 - val_loss: 0.9095\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7563 - val_loss: 0.9073\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7569 - val_loss: 0.9076\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7571 - val_loss: 0.9100\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7560 - val_loss: 0.9113\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7573 - val_loss: 0.9159\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7566 - val_loss: 0.9175\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7575 - val_loss: 0.9171\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7571 - val_loss: 0.9188\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7570 - val_loss: 0.9156\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7580 - val_loss: 0.9103\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7563 - val_loss: 0.9101\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7583 - val_loss: 0.9123\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7583 - val_loss: 0.9123\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7567 - val_loss: 0.9110\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7578 - val_loss: 0.9104\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7563 - val_loss: 0.9112\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7561 - val_loss: 0.9122\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7560 - val_loss: 0.9120\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7578 - val_loss: 0.9114\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7558 - val_loss: 0.9095\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7562 - val_loss: 0.9084\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7572 - val_loss: 0.9072\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.9106\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7573 - val_loss: 0.9091\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7576 - val_loss: 0.9109\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7569 - val_loss: 0.9135\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7562 - val_loss: 0.9122\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7570 - val_loss: 0.9118\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7561 - val_loss: 0.9132\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7572 - val_loss: 0.9116\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7558 - val_loss: 0.9083\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7561 - val_loss: 0.9043\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7574 - val_loss: 0.9136\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7566 - val_loss: 0.9112\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7560 - val_loss: 0.9134\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7565 - val_loss: 0.9112\n",
      "Epoch 383/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7563 - val_loss: 0.9116\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7565 - val_loss: 0.9092\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7564 - val_loss: 0.9058\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7570 - val_loss: 0.9052\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7557 - val_loss: 0.9057\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7560 - val_loss: 0.9061\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7558 - val_loss: 0.9055\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7562 - val_loss: 0.9032\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7556 - val_loss: 0.9013\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7559 - val_loss: 0.9013\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7564 - val_loss: 0.9061\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7571 - val_loss: 0.9085\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7570 - val_loss: 0.9068\n",
      "Epoch 396/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7574 - val_loss: 0.9073\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7563 - val_loss: 0.9048\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7560 - val_loss: 0.9062\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7567 - val_loss: 0.9058\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7568 - val_loss: 0.9126\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7567 - val_loss: 0.9131\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7562 - val_loss: 0.9170\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7570 - val_loss: 0.9125\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7562 - val_loss: 0.9155\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7570 - val_loss: 0.9125\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7576 - val_loss: 0.9088\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7560 - val_loss: 0.9083\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7573 - val_loss: 0.9063\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7558 - val_loss: 0.9084\n",
      "Epoch 410/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7566 - val_loss: 0.9098\n",
      "Epoch 411/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7561 - val_loss: 0.9068\n",
      "Epoch 412/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7560 - val_loss: 0.9069\n",
      "Epoch 413/500\n",
      "105/105 [==============================] - 0s 159us/sample - loss: 0.7581 - val_loss: 0.9083\n",
      "Epoch 414/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7565 - val_loss: 0.9080\n",
      "Epoch 415/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7563 - val_loss: 0.9079\n",
      "Epoch 416/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.9114\n",
      "Epoch 417/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7585 - val_loss: 0.9127\n",
      "Epoch 418/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7564 - val_loss: 0.9134\n",
      "Epoch 419/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7561 - val_loss: 0.9150\n",
      "Epoch 420/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7563 - val_loss: 0.9135\n",
      "Epoch 421/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7570 - val_loss: 0.9118\n",
      "Epoch 422/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7569 - val_loss: 0.9119\n",
      "Epoch 423/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7588 - val_loss: 0.9086\n",
      "Epoch 424/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7563 - val_loss: 0.9072\n",
      "Epoch 425/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.655 - 0s 132us/sample - loss: 0.7580 - val_loss: 0.9096\n",
      "Epoch 426/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7574 - val_loss: 0.9083\n",
      "Epoch 427/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7574 - val_loss: 0.9070\n",
      "Epoch 428/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7562 - val_loss: 0.9050\n",
      "Epoch 429/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7562 - val_loss: 0.9068\n",
      "Epoch 430/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7564 - val_loss: 0.9035\n",
      "Epoch 431/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7562 - val_loss: 0.9036\n",
      "Epoch 432/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7561 - val_loss: 0.9028\n",
      "Epoch 433/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7568 - val_loss: 0.9063\n",
      "Epoch 434/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7574 - val_loss: 0.9104\n",
      "Epoch 435/500\n",
      "105/105 [==============================] - 0s 161us/sample - loss: 0.7574 - val_loss: 0.9135\n",
      "Epoch 436/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7566 - val_loss: 0.9130\n",
      "Epoch 437/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7579 - val_loss: 0.9103\n",
      "Epoch 438/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7573 - val_loss: 0.9122\n",
      "Epoch 439/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7570 - val_loss: 0.9123\n",
      "Epoch 440/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7569 - val_loss: 0.9101\n",
      "Epoch 441/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7577 - val_loss: 0.9076\n",
      "Epoch 442/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7582 - val_loss: 0.9076\n",
      "Epoch 443/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7574 - val_loss: 0.9075\n",
      "Epoch 444/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7574 - val_loss: 0.9095\n",
      "Epoch 445/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7582 - val_loss: 0.9071\n",
      "Epoch 446/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7564 - val_loss: 0.9061\n",
      "Epoch 447/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7567 - val_loss: 0.9128\n",
      "Epoch 448/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7568 - val_loss: 0.9145\n",
      "Epoch 449/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7570 - val_loss: 0.9114\n",
      "Epoch 450/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7569 - val_loss: 0.9113\n",
      "Epoch 451/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7572 - val_loss: 0.9081\n",
      "Epoch 452/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7568 - val_loss: 0.9069\n",
      "Epoch 453/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7570 - val_loss: 0.9066\n",
      "Epoch 454/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7562 - val_loss: 0.9082\n",
      "Epoch 455/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7574 - val_loss: 0.9083\n",
      "Epoch 456/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7563 - val_loss: 0.9059\n",
      "Epoch 457/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7567 - val_loss: 0.9073\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7577 - val_loss: 0.9091\n",
      "Epoch 459/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7560 - val_loss: 0.9077\n",
      "Epoch 460/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7561 - val_loss: 0.9086\n",
      "Epoch 461/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7570 - val_loss: 0.9102\n",
      "Epoch 462/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7564 - val_loss: 0.9099\n",
      "Epoch 463/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7568 - val_loss: 0.9037\n",
      "Epoch 464/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7562 - val_loss: 0.9013\n",
      "Epoch 465/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7581 - val_loss: 0.9002\n",
      "Epoch 466/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7564 - val_loss: 0.8973\n",
      "Epoch 467/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7571 - val_loss: 0.8968\n",
      "Epoch 468/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7564 - val_loss: 0.8958\n",
      "Epoch 469/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7566 - val_loss: 0.8968\n",
      "Epoch 470/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7567 - val_loss: 0.8997\n",
      "Epoch 471/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7568 - val_loss: 0.8966\n",
      "Epoch 472/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7566 - val_loss: 0.8984\n",
      "Epoch 473/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7565 - val_loss: 0.9049\n",
      "Epoch 474/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7560 - val_loss: 0.9049\n",
      "Epoch 475/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7559 - val_loss: 0.9094\n",
      "Epoch 476/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7575 - val_loss: 0.9085\n",
      "Epoch 477/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.9084\n",
      "Epoch 478/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7572 - val_loss: 0.9060\n",
      "Epoch 479/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7562 - val_loss: 0.9042\n",
      "Epoch 480/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7562 - val_loss: 0.9055\n",
      "Epoch 481/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7566 - val_loss: 0.9064\n",
      "Epoch 482/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7568 - val_loss: 0.9067\n",
      "Epoch 483/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7564 - val_loss: 0.9112\n",
      "Epoch 484/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7560 - val_loss: 0.9079\n",
      "Epoch 485/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7574 - val_loss: 0.9063\n",
      "Epoch 486/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7560 - val_loss: 0.9101\n",
      "Epoch 487/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7567 - val_loss: 0.9096\n",
      "Epoch 488/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7575 - val_loss: 0.9138\n",
      "Epoch 489/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7566 - val_loss: 0.9110\n",
      "Epoch 490/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7562 - val_loss: 0.9090\n",
      "Epoch 491/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7558 - val_loss: 0.9067\n",
      "Epoch 492/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7556 - val_loss: 0.9072\n",
      "Epoch 493/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7563 - val_loss: 0.9070\n",
      "Epoch 494/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7557 - val_loss: 0.9051\n",
      "Epoch 495/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7567 - val_loss: 0.9042\n",
      "Epoch 496/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7560 - val_loss: 0.9081\n",
      "Epoch 497/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7564 - val_loss: 0.9100\n",
      "Epoch 498/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7562 - val_loss: 0.9067\n",
      "Epoch 499/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7575 - val_loss: 0.9086\n",
      "Epoch 500/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7562 - val_loss: 0.9131\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=(1,))\n",
    "output = tf.keras.layers.Dense(1)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(1)\n",
    "output = dense(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/Identity:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = tf.keras.layers.Dense(1)\n",
    "dense.__call__(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105 [==============================] - 0s 2ms/sample - loss: 8.1836 - val_loss: 4.8634\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 6.7137 - val_loss: 4.1428\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 5.6262 - val_loss: 3.5354\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 4.6912 - val_loss: 3.0735\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 3.9858 - val_loss: 2.6653\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 3.3637 - val_loss: 2.3041\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 2.8265 - val_loss: 2.0468\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 2.4365 - val_loss: 1.8254\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 2.0978 - val_loss: 1.6499\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 1.8372 - val_loss: 1.4969\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 1.6275 - val_loss: 1.3934\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 1.4642 - val_loss: 1.3162\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 1.3397 - val_loss: 1.2303\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 1.2088 - val_loss: 1.1768\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 1.1303 - val_loss: 1.1296\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 1.0619 - val_loss: 1.0830\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.9967 - val_loss: 1.0537\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.9534 - val_loss: 1.0185\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.9083 - val_loss: 0.9949\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.8765 - val_loss: 0.9768\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.8559 - val_loss: 0.9628\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.8357 - val_loss: 0.9465\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.8180 - val_loss: 0.9415\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.8043 - val_loss: 0.9368\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7954 - val_loss: 0.9339\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7891 - val_loss: 0.9237\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 156us/sample - loss: 0.7822 - val_loss: 0.9203\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7783 - val_loss: 0.9205\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7753 - val_loss: 0.9141\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7707 - val_loss: 0.9121\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7679 - val_loss: 0.9120\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7664 - val_loss: 0.9058\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7631 - val_loss: 0.9063\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7634 - val_loss: 0.9095\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.7614 - val_loss: 0.9088\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7601 - val_loss: 0.9048\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7602 - val_loss: 0.9044\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7589 - val_loss: 0.9029\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7583 - val_loss: 0.8973\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7578 - val_loss: 0.8939\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7583 - val_loss: 0.8919\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7575 - val_loss: 0.8915\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 158us/sample - loss: 0.7586 - val_loss: 0.8946\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7582 - val_loss: 0.8946\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7573 - val_loss: 0.8959\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7576 - val_loss: 0.8964\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7570 - val_loss: 0.8973\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7574 - val_loss: 0.8969\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7575 - val_loss: 0.8969\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7576 - val_loss: 0.8960\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.8980\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7574 - val_loss: 0.8972\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7572 - val_loss: 0.8963\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7571 - val_loss: 0.8965\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7568 - val_loss: 0.8960\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 151us/sample - loss: 0.7566 - val_loss: 0.8963\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7580 - val_loss: 0.8944\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7573 - val_loss: 0.8982\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7558 - val_loss: 0.9003\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7572 - val_loss: 0.9039\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7564 - val_loss: 0.9018\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7565 - val_loss: 0.9006\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7560 - val_loss: 0.9023\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7564 - val_loss: 0.9018\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7579 - val_loss: 0.8980\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7567 - val_loss: 0.8967\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7563 - val_loss: 0.8996\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7572 - val_loss: 0.9019\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7567 - val_loss: 0.8981\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7570 - val_loss: 0.8937\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7588 - val_loss: 0.8930\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7576 - val_loss: 0.8949\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7569 - val_loss: 0.9002\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7565 - val_loss: 0.9013\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7564 - val_loss: 0.9027\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7561 - val_loss: 0.9009\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7562 - val_loss: 0.8989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7562 - val_loss: 0.8968\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7561 - val_loss: 0.8992\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7570 - val_loss: 0.9045\n",
      "Epoch 81/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7563 - val_loss: 0.9030\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7561 - val_loss: 0.9038\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7561 - val_loss: 0.9033\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7563 - val_loss: 0.9104\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7561 - val_loss: 0.9067\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7569 - val_loss: 0.9032\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7558 - val_loss: 0.9023\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7574 - val_loss: 0.9012\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7571 - val_loss: 0.8977\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7571 - val_loss: 0.8973\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7564 - val_loss: 0.8985\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7570 - val_loss: 0.9022\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7570 - val_loss: 0.9009\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7595 - val_loss: 0.9019\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7567 - val_loss: 0.9030\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7563 - val_loss: 0.9047\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7560 - val_loss: 0.9033\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7558 - val_loss: 0.9030\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7558 - val_loss: 0.9033\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7566 - val_loss: 0.9060\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7559 - val_loss: 0.9068\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7558 - val_loss: 0.9076\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7562 - val_loss: 0.9111\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7564 - val_loss: 0.9122\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7574 - val_loss: 0.9074\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7565 - val_loss: 0.9084\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7563 - val_loss: 0.9055\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7560 - val_loss: 0.9033\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7568 - val_loss: 0.9044\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7564 - val_loss: 0.9023\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7565 - val_loss: 0.9012\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7560 - val_loss: 0.9020\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7572 - val_loss: 0.9016\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7559 - val_loss: 0.8990\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7566 - val_loss: 0.9013\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7565 - val_loss: 0.8978\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7565 - val_loss: 0.9020\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7564 - val_loss: 0.9005\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7561 - val_loss: 0.9018\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7558 - val_loss: 0.9024\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7563 - val_loss: 0.9017\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7560 - val_loss: 0.9017\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7556 - val_loss: 0.9019\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7567 - val_loss: 0.9009\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7565 - val_loss: 0.8995\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7568 - val_loss: 0.8967\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7576 - val_loss: 0.8967\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7569 - val_loss: 0.8978\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7560 - val_loss: 0.8964\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7566 - val_loss: 0.8957\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7562 - val_loss: 0.8932\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7575 - val_loss: 0.8913\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7572 - val_loss: 0.8950\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7566 - val_loss: 0.8941\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7570 - val_loss: 0.8955\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7574 - val_loss: 0.8904\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.8906\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7568 - val_loss: 0.8910\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7571 - val_loss: 0.8942\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7577 - val_loss: 0.8955\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7570 - val_loss: 0.8982\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7560 - val_loss: 0.8977\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7564 - val_loss: 0.8961\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7571 - val_loss: 0.8995\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7561 - val_loss: 0.9022\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7565 - val_loss: 0.9017\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7562 - val_loss: 0.9001\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7561 - val_loss: 0.8980\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7570 - val_loss: 0.8996\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7566 - val_loss: 0.8986\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7566 - val_loss: 0.9032\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7566 - val_loss: 0.9097\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7571 - val_loss: 0.9064\n",
      "Epoch 154/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7560 - val_loss: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7563 - val_loss: 0.9022\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7556 - val_loss: 0.9028\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7558 - val_loss: 0.9024\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7557 - val_loss: 0.9009\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7569 - val_loss: 0.8998\n",
      "Epoch 160/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7569 - val_loss: 0.8998\n",
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7558 - val_loss: 0.9009\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7558 - val_loss: 0.9008\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7563 - val_loss: 0.9001\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7574 - val_loss: 0.8999\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7580 - val_loss: 0.8991\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7573 - val_loss: 0.8989\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7573 - val_loss: 0.8991\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7571 - val_loss: 0.8951\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7593 - val_loss: 0.8959\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7574 - val_loss: 0.8971\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7569 - val_loss: 0.8962\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7570 - val_loss: 0.8943\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7583 - val_loss: 0.8975\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7566 - val_loss: 0.9008\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7570 - val_loss: 0.8958\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7578 - val_loss: 0.8952\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7587 - val_loss: 0.8955\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7571 - val_loss: 0.8942\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7570 - val_loss: 0.8923\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7578 - val_loss: 0.8962\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7573 - val_loss: 0.8991\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7564 - val_loss: 0.9013\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7559 - val_loss: 0.9012\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7558 - val_loss: 0.9025\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7563 - val_loss: 0.9023\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7565 - val_loss: 0.8994\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7572 - val_loss: 0.9034\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7565 - val_loss: 0.9022\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7570 - val_loss: 0.9027\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7570 - val_loss: 0.9018\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7566 - val_loss: 0.9006\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7576 - val_loss: 0.9005\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7557 - val_loss: 0.8985\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7567 - val_loss: 0.9011\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7560 - val_loss: 0.9016\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7565 - val_loss: 0.8982\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7559 - val_loss: 0.9004\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7558 - val_loss: 0.9004\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7558 - val_loss: 0.9003\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7561 - val_loss: 0.9014\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7565 - val_loss: 0.9003\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7567 - val_loss: 0.9020\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7572 - val_loss: 0.9025\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7572 - val_loss: 0.9013\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7578 - val_loss: 0.9011\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7569 - val_loss: 0.8997\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7573 - val_loss: 0.9017\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7571 - val_loss: 0.9008\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7567 - val_loss: 0.9000\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7573 - val_loss: 0.9002\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7580 - val_loss: 0.9047\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7573 - val_loss: 0.9063\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7565 - val_loss: 0.9026\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 157us/sample - loss: 0.7568 - val_loss: 0.9044\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7567 - val_loss: 0.9043\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7572 - val_loss: 0.9041\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7564 - val_loss: 0.9005\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7559 - val_loss: 0.8996\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7561 - val_loss: 0.9014\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7566 - val_loss: 0.9041\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7562 - val_loss: 0.9041\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7563 - val_loss: 0.9040\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7562 - val_loss: 0.9050\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7561 - val_loss: 0.9046\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7568 - val_loss: 0.9033\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7571 - val_loss: 0.9035\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7563 - val_loss: 0.9068\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7567 - val_loss: 0.9068\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7557 - val_loss: 0.9053\n",
      "Epoch 230/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7563 - val_loss: 0.9076\n",
      "Epoch 231/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7561 - val_loss: 0.9059\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7558 - val_loss: 0.9056\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7559 - val_loss: 0.9076\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7561 - val_loss: 0.9025\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7575 - val_loss: 0.9056\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7566 - val_loss: 0.9096\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7563 - val_loss: 0.9122\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7576 - val_loss: 0.9124\n",
      "Epoch 239/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7565 - val_loss: 0.9162\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7572 - val_loss: 0.9155\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7589 - val_loss: 0.9152\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7578 - val_loss: 0.9133\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7570 - val_loss: 0.9099\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7567 - val_loss: 0.9138\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.9140\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7577 - val_loss: 0.9179\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7586 - val_loss: 0.9201\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7583 - val_loss: 0.9174\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7580 - val_loss: 0.9149\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7575 - val_loss: 0.9146\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7573 - val_loss: 0.9137\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7564 - val_loss: 0.9128\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.9125\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7574 - val_loss: 0.9150\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7575 - val_loss: 0.9128\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7577 - val_loss: 0.9097\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7559 - val_loss: 0.9097\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7563 - val_loss: 0.9081\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7563 - val_loss: 0.9067\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7559 - val_loss: 0.9052\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7557 - val_loss: 0.9061\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7567 - val_loss: 0.9045\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7560 - val_loss: 0.9034\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7557 - val_loss: 0.9027\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7563 - val_loss: 0.9045\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7563 - val_loss: 0.9096\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7558 - val_loss: 0.9068\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7568 - val_loss: 0.9099\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7566 - val_loss: 0.9065\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7574 - val_loss: 0.9036\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7559 - val_loss: 0.9044\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7562 - val_loss: 0.9020\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7573 - val_loss: 0.9072\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7563 - val_loss: 0.9084\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7571 - val_loss: 0.9044\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7564 - val_loss: 0.9116\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7577 - val_loss: 0.9111\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7565 - val_loss: 0.9135\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7567 - val_loss: 0.9088\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7573 - val_loss: 0.9083\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7568 - val_loss: 0.9093\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7567 - val_loss: 0.9087\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7562 - val_loss: 0.9072\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7559 - val_loss: 0.9054\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7561 - val_loss: 0.9058\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7573 - val_loss: 0.9057\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7559 - val_loss: 0.9057\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7560 - val_loss: 0.9033\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7563 - val_loss: 0.9020\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7563 - val_loss: 0.9027\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7568 - val_loss: 0.9015\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7557 - val_loss: 0.9021\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7563 - val_loss: 0.9038\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7563 - val_loss: 0.9056\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7576 - val_loss: 0.9131\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7574 - val_loss: 0.9180\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7573 - val_loss: 0.9118\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7574 - val_loss: 0.9109\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7577 - val_loss: 0.9042\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7567 - val_loss: 0.9069\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7562 - val_loss: 0.9054\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7567 - val_loss: 0.9006\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7566 - val_loss: 0.9025\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 158us/sample - loss: 0.7574 - val_loss: 0.9016\n",
      "Epoch 306/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7563 - val_loss: 0.9011\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7567 - val_loss: 0.9034\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7561 - val_loss: 0.9038\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7572 - val_loss: 0.9040\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7557 - val_loss: 0.9040\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7562 - val_loss: 0.9018\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7559 - val_loss: 0.9032\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7578 - val_loss: 0.9025\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7563 - val_loss: 0.9045\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7563 - val_loss: 0.9058\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7561 - val_loss: 0.9037\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7558 - val_loss: 0.9035\n",
      "Epoch 318/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7562 - val_loss: 0.9041\n",
      "Epoch 319/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7565 - val_loss: 0.9023\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7571 - val_loss: 0.9063\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7562 - val_loss: 0.9044\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7586 - val_loss: 0.9037\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7569 - val_loss: 0.9077\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7562 - val_loss: 0.9103\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7562 - val_loss: 0.9106\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7570 - val_loss: 0.9074\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7559 - val_loss: 0.9024\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7559 - val_loss: 0.9026\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7569 - val_loss: 0.9043\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7558 - val_loss: 0.9057\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7572 - val_loss: 0.9080\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7561 - val_loss: 0.9113\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7558 - val_loss: 0.9131\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7566 - val_loss: 0.9111\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7565 - val_loss: 0.9115\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7563 - val_loss: 0.9120\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7591 - val_loss: 0.9140\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7568 - val_loss: 0.9188\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7570 - val_loss: 0.9162\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7580 - val_loss: 0.9118\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7566 - val_loss: 0.9103\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7563 - val_loss: 0.9076\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7564 - val_loss: 0.9080\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7556 - val_loss: 0.9098\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7566 - val_loss: 0.9083\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7562 - val_loss: 0.9065\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7570 - val_loss: 0.9021\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7558 - val_loss: 0.9015\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7558 - val_loss: 0.8982\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7565 - val_loss: 0.8957\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7565 - val_loss: 0.8970\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7575 - val_loss: 0.8958\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7570 - val_loss: 0.8981\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7565 - val_loss: 0.8968\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7585 - val_loss: 0.8986\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7560 - val_loss: 0.8976\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7567 - val_loss: 0.8971\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7562 - val_loss: 0.8941\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7588 - val_loss: 0.8941\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7579 - val_loss: 0.9009\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7598 - val_loss: 0.9055\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7567 - val_loss: 0.9026\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7565 - val_loss: 0.9014\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7574 - val_loss: 0.9053\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7558 - val_loss: 0.9030\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7572 - val_loss: 0.9001\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7558 - val_loss: 0.8993\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7562 - val_loss: 0.8989\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7582 - val_loss: 0.8983\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7568 - val_loss: 0.8985\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7570 - val_loss: 0.9015\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7576 - val_loss: 0.9041\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7580 - val_loss: 0.8988\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7570 - val_loss: 0.8999\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7564 - val_loss: 0.9001\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7579 - val_loss: 0.9020\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7569 - val_loss: 0.9005\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7569 - val_loss: 0.9020\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7563 - val_loss: 0.9058\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7562 - val_loss: 0.9041\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7571 - val_loss: 0.9036\n",
      "Epoch 382/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7559 - val_loss: 0.9039\n",
      "Epoch 383/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7563 - val_loss: 0.9028\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7570 - val_loss: 0.8980\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7575 - val_loss: 0.8953\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7590 - val_loss: 0.8960\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7572 - val_loss: 0.8939\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 146us/sample - loss: 0.7585 - val_loss: 0.8950\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7577 - val_loss: 0.9014\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7571 - val_loss: 0.9011\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 152us/sample - loss: 0.7566 - val_loss: 0.9011\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7565 - val_loss: 0.8982\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7569 - val_loss: 0.9029\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7572 - val_loss: 0.9023\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7571 - val_loss: 0.9002\n",
      "Epoch 396/500\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7559 - val_loss: 0.9000\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7568 - val_loss: 0.9059\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7564 - val_loss: 0.9138\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7566 - val_loss: 0.9145\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7570 - val_loss: 0.9098\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7572 - val_loss: 0.9093\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7573 - val_loss: 0.9078\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7563 - val_loss: 0.9087\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7558 - val_loss: 0.9096\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7557 - val_loss: 0.9085\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7589 - val_loss: 0.9073\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7568 - val_loss: 0.9055\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7570 - val_loss: 0.9057\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7560 - val_loss: 0.9037\n",
      "Epoch 410/500\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 411/500\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7558 - val_loss: 0.9026\n",
      "Epoch 412/500\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7562 - val_loss: 0.9048\n",
      "Epoch 413/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7560 - val_loss: 0.9034\n",
      "Epoch 414/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7567 - val_loss: 0.9045\n",
      "Epoch 415/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7555 - val_loss: 0.9048\n",
      "Epoch 416/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7569 - val_loss: 0.9049\n",
      "Epoch 417/500\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7560 - val_loss: 0.9057\n",
      "Epoch 418/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7574 - val_loss: 0.9053\n",
      "Epoch 419/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7565 - val_loss: 0.9060\n",
      "Epoch 420/500\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7577 - val_loss: 0.9061\n",
      "Epoch 421/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7563 - val_loss: 0.9043\n",
      "Epoch 422/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7572 - val_loss: 0.9034\n",
      "Epoch 423/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7571 - val_loss: 0.9050\n",
      "Epoch 424/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7574 - val_loss: 0.9016\n",
      "Epoch 425/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7565 - val_loss: 0.9012\n",
      "Epoch 426/500\n",
      "105/105 [==============================] - 0s 141us/sample - loss: 0.7614 - val_loss: 0.8996\n",
      "Epoch 427/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7559 - val_loss: 0.9002\n",
      "Epoch 428/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7561 - val_loss: 0.9022\n",
      "Epoch 429/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7581 - val_loss: 0.9058\n",
      "Epoch 430/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7560 - val_loss: 0.9024\n",
      "Epoch 431/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7559 - val_loss: 0.9003\n",
      "Epoch 432/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7562 - val_loss: 0.9003\n",
      "Epoch 433/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7566 - val_loss: 0.9080\n",
      "Epoch 434/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7563 - val_loss: 0.9049\n",
      "Epoch 435/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7559 - val_loss: 0.9044\n",
      "Epoch 436/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7567 - val_loss: 0.9083\n",
      "Epoch 437/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7559 - val_loss: 0.9104\n",
      "Epoch 438/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7564 - val_loss: 0.9065\n",
      "Epoch 439/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7563 - val_loss: 0.9056\n",
      "Epoch 440/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7565 - val_loss: 0.9128\n",
      "Epoch 441/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7567 - val_loss: 0.9108\n",
      "Epoch 442/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7578 - val_loss: 0.9102\n",
      "Epoch 443/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7560 - val_loss: 0.9093\n",
      "Epoch 444/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7568 - val_loss: 0.9100\n",
      "Epoch 445/500\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7566 - val_loss: 0.9068\n",
      "Epoch 446/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7562 - val_loss: 0.9055\n",
      "Epoch 447/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7565 - val_loss: 0.9067\n",
      "Epoch 448/500\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7575 - val_loss: 0.9063\n",
      "Epoch 449/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7575 - val_loss: 0.9067\n",
      "Epoch 450/500\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7562 - val_loss: 0.9058\n",
      "Epoch 451/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7564 - val_loss: 0.9030\n",
      "Epoch 452/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 453/500\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7564 - val_loss: 0.9019\n",
      "Epoch 454/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7569 - val_loss: 0.9101\n",
      "Epoch 455/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7583 - val_loss: 0.9075\n",
      "Epoch 456/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7562 - val_loss: 0.9076\n",
      "Epoch 457/500\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7587 - val_loss: 0.9059\n",
      "Epoch 458/500\n",
      "105/105 [==============================] - 0s 144us/sample - loss: 0.7565 - val_loss: 0.9050\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7560 - val_loss: 0.9096\n",
      "Epoch 460/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7566 - val_loss: 0.9089\n",
      "Epoch 461/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7558 - val_loss: 0.9085\n",
      "Epoch 462/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7563 - val_loss: 0.9082\n",
      "Epoch 463/500\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7562 - val_loss: 0.9081\n",
      "Epoch 464/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7561 - val_loss: 0.9089\n",
      "Epoch 465/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7560 - val_loss: 0.9070\n",
      "Epoch 466/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7560 - val_loss: 0.9074\n",
      "Epoch 467/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7558 - val_loss: 0.9044\n",
      "Epoch 468/500\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7556 - val_loss: 0.9035\n",
      "Epoch 469/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7564 - val_loss: 0.8988\n",
      "Epoch 470/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7561 - val_loss: 0.8967\n",
      "Epoch 471/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7562 - val_loss: 0.8953\n",
      "Epoch 472/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7566 - val_loss: 0.8935\n",
      "Epoch 473/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7574 - val_loss: 0.8947\n",
      "Epoch 474/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7567 - val_loss: 0.8962\n",
      "Epoch 475/500\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7571 - val_loss: 0.9053\n",
      "Epoch 476/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7572 - val_loss: 0.9041\n",
      "Epoch 477/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7574 - val_loss: 0.9006\n",
      "Epoch 478/500\n",
      "105/105 [==============================] - 0s 154us/sample - loss: 0.7564 - val_loss: 0.9028\n",
      "Epoch 479/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7567 - val_loss: 0.9043\n",
      "Epoch 480/500\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7567 - val_loss: 0.9078\n",
      "Epoch 481/500\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7580 - val_loss: 0.9046\n",
      "Epoch 482/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7580 - val_loss: 0.9117\n",
      "Epoch 483/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7573 - val_loss: 0.9133\n",
      "Epoch 484/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7568 - val_loss: 0.9081\n",
      "Epoch 485/500\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7563 - val_loss: 0.9113\n",
      "Epoch 486/500\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7566 - val_loss: 0.9100\n",
      "Epoch 487/500\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7557 - val_loss: 0.9080\n",
      "Epoch 488/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7558 - val_loss: 0.9053\n",
      "Epoch 489/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7564 - val_loss: 0.9026\n",
      "Epoch 490/500\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7563 - val_loss: 0.9019\n",
      "Epoch 491/500\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7559 - val_loss: 0.8993\n",
      "Epoch 492/500\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7575 - val_loss: 0.9000\n",
      "Epoch 493/500\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 0.7562 - val_loss: 0.8995\n",
      "Epoch 494/500\n",
      "105/105 [==============================] - 0s 135us/sample - loss: 0.7560 - val_loss: 0.8989\n",
      "Epoch 495/500\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7563 - val_loss: 0.9007\n",
      "Epoch 496/500\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7562 - val_loss: 0.8971\n",
      "Epoch 497/500\n",
      "105/105 [==============================] - 0s 148us/sample - loss: 0.7563 - val_loss: 0.9024\n",
      "Epoch 498/500\n",
      "105/105 [==============================] - 0s 150us/sample - loss: 0.7565 - val_loss: 0.9024\n",
      "Epoch 499/500\n",
      "105/105 [==============================] - 0s 145us/sample - loss: 0.7561 - val_loss: 0.9016\n",
      "Epoch 500/500\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7564 - val_loss: 0.9025\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "model.load_weights('simple_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 679us/sample - loss: 0.9471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9470952200889587"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 694us/sample - loss: 0.9471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9470952200889587"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('simple_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/500\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 8.6965 - val_loss: 4.7182\n",
      "Epoch 2/500\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 7.2260 - val_loss: 3.9015\n",
      "Epoch 3/500\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 6.0244 - val_loss: 3.2475\n",
      "Epoch 4/500\n",
      "120/120 [==============================] - 0s 164us/sample - loss: 5.0570 - val_loss: 2.7286\n",
      "Epoch 5/500\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 4.2667 - val_loss: 2.3038\n",
      "Epoch 6/500\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 3.6147 - val_loss: 1.9772\n",
      "Epoch 7/500\n",
      "120/120 [==============================] - 0s 176us/sample - loss: 3.0982 - val_loss: 1.7149\n",
      "Epoch 8/500\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 2.6801 - val_loss: 1.5040\n",
      "Epoch 9/500\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 2.3281 - val_loss: 1.3362\n",
      "Epoch 10/500\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 2.0438 - val_loss: 1.2032\n",
      "Epoch 11/500\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 1.8162 - val_loss: 1.1042\n",
      "Epoch 12/500\n",
      "120/120 [==============================] - 0s 169us/sample - loss: 1.6301 - val_loss: 1.0236\n",
      "Epoch 13/500\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 1.4755 - val_loss: 0.9602\n",
      "Epoch 14/500\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 1.3488 - val_loss: 0.9101\n",
      "Epoch 15/500\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.2444 - val_loss: 0.8715\n",
      "Epoch 16/500\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 1.1575 - val_loss: 0.8436\n",
      "Epoch 17/500\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 1.0898 - val_loss: 0.8230\n",
      "Epoch 18/500\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 1.0355 - val_loss: 0.8067\n",
      "Epoch 19/500\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 0.9888 - val_loss: 0.7963\n",
      "Epoch 20/500\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.9541 - val_loss: 0.7902\n",
      "Epoch 21/500\n",
      "120/120 [==============================] - 0s 164us/sample - loss: 0.9255 - val_loss: 0.7860\n",
      "Epoch 22/500\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.9017 - val_loss: 0.7828\n",
      "Epoch 23/500\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.8810 - val_loss: 0.7813\n",
      "Epoch 24/500\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.8629 - val_loss: 0.7816\n",
      "Epoch 25/500\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.8492 - val_loss: 0.7828\n",
      "Epoch 26/500\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.8403 - val_loss: 0.7841\n",
      "Epoch 27/500\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.8295 - val_loss: 0.7863\n",
      "Epoch 28/500\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.8212 - val_loss: 0.7890\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "callback_list = [tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', monitor='val_loss', save_best_only=True),\n",
    "                 tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 468us/sample - loss: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9946151375770569"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('simple_model.h5')\n",
    "model.load_weights('my_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_arr = np.arange(-2, 2, 0.1)\n",
    "y_arr = model.predict(x_arr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr, '-r', lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/300\n",
      "105/105 [==============================] - 0s 1ms/sample - loss: 0.7570 - val_loss: 0.9094\n",
      "Epoch 2/300\n",
      "105/105 [==============================] - 0s 139us/sample - loss: 0.7568 - val_loss: 0.9088\n",
      "Epoch 3/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7563 - val_loss: 0.9072\n",
      "Epoch 4/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7574 - val_loss: 0.9085\n",
      "Epoch 5/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7567 - val_loss: 0.9078\n",
      "Epoch 6/300\n",
      "105/105 [==============================] - 0s 138us/sample - loss: 0.7575 - val_loss: 0.9068\n",
      "Epoch 7/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7577 - val_loss: 0.9062\n",
      "Epoch 8/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7568 - val_loss: 0.9041\n",
      "Epoch 9/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7559 - val_loss: 0.9027\n",
      "Epoch 10/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7557 - val_loss: 0.9039\n",
      "Epoch 11/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7578 - val_loss: 0.9056\n",
      "Epoch 12/300\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7562 - val_loss: 0.9034\n",
      "Epoch 13/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7559 - val_loss: 0.9026\n",
      "Epoch 14/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7555 - val_loss: 0.9020\n",
      "Epoch 15/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7555 - val_loss: 0.9035\n",
      "Epoch 16/300\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7575 - val_loss: 0.9014\n",
      "Epoch 17/300\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7559 - val_loss: 0.9021\n",
      "Epoch 18/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7562 - val_loss: 0.9030\n",
      "Epoch 19/300\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7559 - val_loss: 0.9023\n",
      "Epoch 20/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7566 - val_loss: 0.9087\n",
      "Epoch 21/300\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7582 - val_loss: 0.9093\n",
      "Epoch 22/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7559 - val_loss: 0.9080\n",
      "Epoch 23/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7569 - val_loss: 0.9093\n",
      "Epoch 24/300\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7557 - val_loss: 0.9068\n",
      "Epoch 25/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 26/300\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7562 - val_loss: 0.9035\n",
      "Epoch 27/300\n",
      "105/105 [==============================] - 0s 143us/sample - loss: 0.7560 - val_loss: 0.9049\n",
      "Epoch 28/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7567 - val_loss: 0.9037\n",
      "Epoch 29/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7560 - val_loss: 0.9035\n",
      "Epoch 30/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7572 - val_loss: 0.9041\n",
      "Epoch 31/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7562 - val_loss: 0.9099\n",
      "Epoch 32/300\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7571 - val_loss: 0.9073\n",
      "Epoch 33/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7559 - val_loss: 0.9092\n",
      "Epoch 34/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7565 - val_loss: 0.9067\n",
      "Epoch 35/300\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.7559 - val_loss: 0.9045\n",
      "Epoch 36/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7558 - val_loss: 0.9034\n",
      "Epoch 37/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7560 - val_loss: 0.9034\n",
      "Epoch 38/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7564 - val_loss: 0.9029\n",
      "Epoch 39/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7560 - val_loss: 0.9034\n",
      "Epoch 40/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7571 - val_loss: 0.9067\n",
      "Epoch 41/300\n",
      "105/105 [==============================] - 0s 140us/sample - loss: 0.7564 - val_loss: 0.9051\n",
      "Epoch 42/300\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7595 - val_loss: 0.9040\n",
      "Epoch 43/300\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7564 - val_loss: 0.9023\n",
      "Epoch 44/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7578 - val_loss: 0.9017\n",
      "Epoch 45/300\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7567 - val_loss: 0.9009\n",
      "Epoch 46/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7566 - val_loss: 0.9023\n",
      "Epoch 47/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7569 - val_loss: 0.8987\n",
      "Epoch 48/300\n",
      "105/105 [==============================] - 0s 134us/sample - loss: 0.7581 - val_loss: 0.8951\n",
      "Epoch 49/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7586 - val_loss: 0.8926\n",
      "Epoch 50/300\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7575 - val_loss: 0.8967\n",
      "Epoch 51/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7580 - val_loss: 0.8935\n",
      "Epoch 52/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7574 - val_loss: 0.8960\n",
      "Epoch 53/300\n",
      "105/105 [==============================] - 0s 137us/sample - loss: 0.7569 - val_loss: 0.8934\n",
      "Epoch 54/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7586 - val_loss: 0.8948\n",
      "Epoch 55/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7581 - val_loss: 0.8959\n",
      "Epoch 56/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7564 - val_loss: 0.8988\n",
      "Epoch 57/300\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7578 - val_loss: 0.8961\n",
      "Epoch 58/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7563 - val_loss: 0.8947\n",
      "Epoch 59/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7578 - val_loss: 0.8976\n",
      "Epoch 60/300\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.7566 - val_loss: 0.8936\n",
      "Epoch 61/300\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7569 - val_loss: 0.8949\n",
      "Epoch 62/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7578 - val_loss: 0.8951\n",
      "Epoch 63/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7586 - val_loss: 0.8972\n",
      "Epoch 64/300\n",
      "105/105 [==============================] - 0s 142us/sample - loss: 0.7564 - val_loss: 0.8964\n",
      "Epoch 65/300\n",
      "105/105 [==============================] - 0s 149us/sample - loss: 0.7562 - val_loss: 0.9008\n",
      "Epoch 66/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7569 - val_loss: 0.9027\n",
      "Epoch 67/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7566 - val_loss: 0.9014\n",
      "Epoch 68/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7558 - val_loss: 0.8999\n",
      "Epoch 69/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7559 - val_loss: 0.9009\n",
      "Epoch 70/300\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.7568 - val_loss: 0.9012\n",
      "Epoch 71/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7576 - val_loss: 0.9030\n",
      "Epoch 72/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7572 - val_loss: 0.9048\n",
      "Epoch 73/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7563 - val_loss: 0.9041\n",
      "Epoch 74/300\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.7566 - val_loss: 0.9043\n",
      "Epoch 75/300\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7561 - val_loss: 0.9005\n",
      "Epoch 76/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7564 - val_loss: 0.8997\n",
      "Epoch 77/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7566 - val_loss: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7572 - val_loss: 0.9047\n",
      "Epoch 79/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7557 - val_loss: 0.9046\n",
      "Epoch 80/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7567 - val_loss: 0.9082\n",
      "Epoch 81/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7563 - val_loss: 0.9100\n",
      "Epoch 82/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7580 - val_loss: 0.9081\n",
      "Epoch 83/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7560 - val_loss: 0.9064\n",
      "Epoch 84/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7564 - val_loss: 0.9118\n",
      "Epoch 85/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7571 - val_loss: 0.9088\n",
      "Epoch 86/300\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.7572 - val_loss: 0.9102\n",
      "Epoch 87/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7562 - val_loss: 0.9102\n",
      "Epoch 88/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7561 - val_loss: 0.9109\n",
      "Epoch 89/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7575 - val_loss: 0.9111\n",
      "Epoch 90/300\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.7559 - val_loss: 0.9110\n",
      "Epoch 91/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7562 - val_loss: 0.9105\n",
      "Epoch 92/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7568 - val_loss: 0.9090\n",
      "Epoch 93/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7571 - val_loss: 0.9056\n",
      "Epoch 94/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7564 - val_loss: 0.9043\n",
      "Epoch 95/300\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7561 - val_loss: 0.9028\n",
      "Epoch 96/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7569 - val_loss: 0.9040\n",
      "Epoch 97/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7557 - val_loss: 0.9067\n",
      "Epoch 98/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7558 - val_loss: 0.9062\n",
      "Epoch 99/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7561 - val_loss: 0.9059\n",
      "Epoch 100/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7556 - val_loss: 0.9027\n",
      "Epoch 101/300\n",
      "105/105 [==============================] - 0s 100us/sample - loss: 0.7569 - val_loss: 0.9021\n",
      "Epoch 102/300\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.7566 - val_loss: 0.9015\n",
      "Epoch 103/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7560 - val_loss: 0.9030\n",
      "Epoch 104/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7559 - val_loss: 0.9045\n",
      "Epoch 105/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7563 - val_loss: 0.9045\n",
      "Epoch 106/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7566 - val_loss: 0.9063\n",
      "Epoch 107/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7565 - val_loss: 0.9090\n",
      "Epoch 108/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7566 - val_loss: 0.9064\n",
      "Epoch 109/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7558 - val_loss: 0.9058\n",
      "Epoch 110/300\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7564 - val_loss: 0.9079\n",
      "Epoch 111/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7566 - val_loss: 0.9068\n",
      "Epoch 112/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7566 - val_loss: 0.9089\n",
      "Epoch 113/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7557 - val_loss: 0.9071\n",
      "Epoch 114/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7555 - val_loss: 0.9059\n",
      "Epoch 115/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7561 - val_loss: 0.9055\n",
      "Epoch 116/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7571 - val_loss: 0.9037\n",
      "Epoch 117/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7576 - val_loss: 0.9041\n",
      "Epoch 118/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7566 - val_loss: 0.9064\n",
      "Epoch 119/300\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.7556 - val_loss: 0.9046\n",
      "Epoch 120/300\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7566 - val_loss: 0.9071\n",
      "Epoch 121/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7557 - val_loss: 0.9075\n",
      "Epoch 122/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7573 - val_loss: 0.9048\n",
      "Epoch 123/300\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.7568 - val_loss: 0.9063\n",
      "Epoch 124/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7559 - val_loss: 0.9054\n",
      "Epoch 125/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7568 - val_loss: 0.9010\n",
      "Epoch 126/300\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.7571 - val_loss: 0.9023\n",
      "Epoch 127/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7568 - val_loss: 0.9040\n",
      "Epoch 128/300\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7562 - val_loss: 0.9056\n",
      "Epoch 129/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7567 - val_loss: 0.9048\n",
      "Epoch 130/300\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.7563 - val_loss: 0.9054\n",
      "Epoch 131/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7566 - val_loss: 0.9038\n",
      "Epoch 132/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7569 - val_loss: 0.9103\n",
      "Epoch 133/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7559 - val_loss: 0.9098\n",
      "Epoch 134/300\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7567 - val_loss: 0.9059\n",
      "Epoch 135/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7592 - val_loss: 0.9066\n",
      "Epoch 136/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7559 - val_loss: 0.9082\n",
      "Epoch 137/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7563 - val_loss: 0.9093\n",
      "Epoch 138/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7561 - val_loss: 0.9089\n",
      "Epoch 139/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7560 - val_loss: 0.9041\n",
      "Epoch 140/300\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7560 - val_loss: 0.9024\n",
      "Epoch 141/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7559 - val_loss: 0.9012\n",
      "Epoch 142/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7557 - val_loss: 0.9022\n",
      "Epoch 143/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7562 - val_loss: 0.9037\n",
      "Epoch 144/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7558 - val_loss: 0.9033\n",
      "Epoch 145/300\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7566 - val_loss: 0.9002\n",
      "Epoch 146/300\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.7568 - val_loss: 0.8999\n",
      "Epoch 147/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7568 - val_loss: 0.9022\n",
      "Epoch 148/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7562 - val_loss: 0.9018\n",
      "Epoch 149/300\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7564 - val_loss: 0.9033\n",
      "Epoch 150/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7568 - val_loss: 0.9037\n",
      "Epoch 151/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7573 - val_loss: 0.9037\n",
      "Epoch 152/300\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7565 - val_loss: 0.9017\n",
      "Epoch 153/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7568 - val_loss: 0.9073\n",
      "Epoch 154/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7566 - val_loss: 0.9084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7569 - val_loss: 0.9065\n",
      "Epoch 156/300\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7576 - val_loss: 0.9112\n",
      "Epoch 157/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7560 - val_loss: 0.9075\n",
      "Epoch 158/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7562 - val_loss: 0.9058\n",
      "Epoch 159/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7573 - val_loss: 0.9037\n",
      "Epoch 160/300\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7559 - val_loss: 0.9059\n",
      "Epoch 161/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7558 - val_loss: 0.9074\n",
      "Epoch 162/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7556 - val_loss: 0.9083\n",
      "Epoch 163/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7561 - val_loss: 0.9080\n",
      "Epoch 164/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7558 - val_loss: 0.9050\n",
      "Epoch 165/300\n",
      "105/105 [==============================] - 0s 136us/sample - loss: 0.7570 - val_loss: 0.9003\n",
      "Epoch 166/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7576 - val_loss: 0.8981\n",
      "Epoch 167/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7572 - val_loss: 0.9024\n",
      "Epoch 168/300\n",
      "105/105 [==============================] - 0s 147us/sample - loss: 0.7577 - val_loss: 0.9028\n",
      "Epoch 169/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7556 - val_loss: 0.9055\n",
      "Epoch 170/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7558 - val_loss: 0.9053\n",
      "Epoch 171/300\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7560 - val_loss: 0.9025\n",
      "Epoch 172/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7567 - val_loss: 0.9011\n",
      "Epoch 173/300\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7561 - val_loss: 0.9009\n",
      "Epoch 174/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7562 - val_loss: 0.9068\n",
      "Epoch 175/300\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7564 - val_loss: 0.9078\n",
      "Epoch 176/300\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.7581 - val_loss: 0.9164\n",
      "Epoch 177/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7571 - val_loss: 0.9150\n",
      "Epoch 178/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7584 - val_loss: 0.9148\n",
      "Epoch 179/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7572 - val_loss: 0.9114\n",
      "Epoch 180/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7562 - val_loss: 0.9070\n",
      "Epoch 181/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7561 - val_loss: 0.9085\n",
      "Epoch 182/300\n",
      "105/105 [==============================] - 0s 94us/sample - loss: 0.7560 - val_loss: 0.9079\n",
      "Epoch 183/300\n",
      "105/105 [==============================] - 0s 101us/sample - loss: 0.7568 - val_loss: 0.9117\n",
      "Epoch 184/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7559 - val_loss: 0.9126\n",
      "Epoch 185/300\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.7567 - val_loss: 0.9125\n",
      "Epoch 186/300\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7580 - val_loss: 0.9090\n",
      "Epoch 187/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7571 - val_loss: 0.9096\n",
      "Epoch 188/300\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7560 - val_loss: 0.9107\n",
      "Epoch 189/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7561 - val_loss: 0.9097\n",
      "Epoch 190/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7579 - val_loss: 0.9085\n",
      "Epoch 191/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7580 - val_loss: 0.9069\n",
      "Epoch 192/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7564 - val_loss: 0.9115\n",
      "Epoch 193/300\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7558 - val_loss: 0.9096\n",
      "Epoch 194/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7573 - val_loss: 0.9027\n",
      "Epoch 195/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7569 - val_loss: 0.9113\n",
      "Epoch 196/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7560 - val_loss: 0.9103\n",
      "Epoch 197/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7557 - val_loss: 0.9102\n",
      "Epoch 198/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7559 - val_loss: 0.9079\n",
      "Epoch 199/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7557 - val_loss: 0.9073\n",
      "Epoch 200/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7570 - val_loss: 0.9075\n",
      "Epoch 201/300\n",
      "105/105 [==============================] - 0s 124us/sample - loss: 0.7564 - val_loss: 0.9070\n",
      "Epoch 202/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7601 - val_loss: 0.9008\n",
      "Epoch 203/300\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7558 - val_loss: 0.9009\n",
      "Epoch 204/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7571 - val_loss: 0.9022\n",
      "Epoch 205/300\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7563 - val_loss: 0.9027\n",
      "Epoch 206/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7567 - val_loss: 0.9043\n",
      "Epoch 207/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7564 - val_loss: 0.9043\n",
      "Epoch 208/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7564 - val_loss: 0.9057\n",
      "Epoch 209/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7561 - val_loss: 0.9032\n",
      "Epoch 210/300\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7559 - val_loss: 0.9052\n",
      "Epoch 211/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7561 - val_loss: 0.9066\n",
      "Epoch 212/300\n",
      "105/105 [==============================] - 0s 98us/sample - loss: 0.7563 - val_loss: 0.9079\n",
      "Epoch 213/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7571 - val_loss: 0.9052\n",
      "Epoch 214/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7573 - val_loss: 0.9020\n",
      "Epoch 215/300\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7571 - val_loss: 0.8988\n",
      "Epoch 216/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7561 - val_loss: 0.8963\n",
      "Epoch 217/300\n",
      "105/105 [==============================] - 0s 130us/sample - loss: 0.7570 - val_loss: 0.8956\n",
      "Epoch 218/300\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 0.7574 - val_loss: 0.8974\n",
      "Epoch 219/300\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7559 - val_loss: 0.8961\n",
      "Epoch 220/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7569 - val_loss: 0.9031\n",
      "Epoch 221/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7563 - val_loss: 0.9007\n",
      "Epoch 222/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7571 - val_loss: 0.9054\n",
      "Epoch 223/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7567 - val_loss: 0.9060\n",
      "Epoch 224/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7565 - val_loss: 0.9083\n",
      "Epoch 225/300\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.7572 - val_loss: 0.9084\n",
      "Epoch 226/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7572 - val_loss: 0.9060\n",
      "Epoch 227/300\n",
      "105/105 [==============================] - 0s 129us/sample - loss: 0.7573 - val_loss: 0.9066\n",
      "Epoch 228/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7597 - val_loss: 0.9074\n",
      "Epoch 229/300\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7569 - val_loss: 0.9096\n",
      "Epoch 230/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7557 - val_loss: 0.9122\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7570 - val_loss: 0.9093\n",
      "Epoch 232/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7564 - val_loss: 0.9087\n",
      "Epoch 233/300\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.7570 - val_loss: 0.9089\n",
      "Epoch 234/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7567 - val_loss: 0.9072\n",
      "Epoch 235/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7561 - val_loss: 0.9013\n",
      "Epoch 236/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7584 - val_loss: 0.8977\n",
      "Epoch 237/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7571 - val_loss: 0.8928\n",
      "Epoch 238/300\n",
      "105/105 [==============================] - 0s 96us/sample - loss: 0.7577 - val_loss: 0.8922\n",
      "Epoch 239/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7571 - val_loss: 0.8926\n",
      "Epoch 240/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7574 - val_loss: 0.8906\n",
      "Epoch 241/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7588 - val_loss: 0.8908\n",
      "Epoch 242/300\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.7576 - val_loss: 0.8911\n",
      "Epoch 243/300\n",
      "105/105 [==============================] - 0s 115us/sample - loss: 0.7574 - val_loss: 0.8938\n",
      "Epoch 244/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7563 - val_loss: 0.8937\n",
      "Epoch 245/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7569 - val_loss: 0.8950\n",
      "Epoch 246/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7564 - val_loss: 0.8927\n",
      "Epoch 247/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7573 - val_loss: 0.8934\n",
      "Epoch 248/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7584 - val_loss: 0.8957\n",
      "Epoch 249/300\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7564 - val_loss: 0.8993\n",
      "Epoch 250/300\n",
      "105/105 [==============================] - 0s 107us/sample - loss: 0.7565 - val_loss: 0.9040\n",
      "Epoch 251/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7568 - val_loss: 0.9064\n",
      "Epoch 252/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7573 - val_loss: 0.9091\n",
      "Epoch 253/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7558 - val_loss: 0.9123\n",
      "Epoch 254/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7577 - val_loss: 0.9151\n",
      "Epoch 255/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7572 - val_loss: 0.9160\n",
      "Epoch 256/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7568 - val_loss: 0.9184\n",
      "Epoch 257/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7581 - val_loss: 0.9157\n",
      "Epoch 258/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7567 - val_loss: 0.9200\n",
      "Epoch 259/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7571 - val_loss: 0.9168\n",
      "Epoch 260/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7564 - val_loss: 0.9152\n",
      "Epoch 261/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.7561 - val_loss: 0.9158\n",
      "Epoch 262/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7569 - val_loss: 0.9202\n",
      "Epoch 263/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7583 - val_loss: 0.9143\n",
      "Epoch 264/300\n",
      "105/105 [==============================] - 0s 113us/sample - loss: 0.7567 - val_loss: 0.9141\n",
      "Epoch 265/300\n",
      "105/105 [==============================] - 0s 106us/sample - loss: 0.7570 - val_loss: 0.9062\n",
      "Epoch 266/300\n",
      "105/105 [==============================] - 0s 122us/sample - loss: 0.7566 - val_loss: 0.9070\n",
      "Epoch 267/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7564 - val_loss: 0.9077\n",
      "Epoch 268/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7561 - val_loss: 0.9111\n",
      "Epoch 269/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7590 - val_loss: 0.9048\n",
      "Epoch 270/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7564 - val_loss: 0.9108\n",
      "Epoch 271/300\n",
      "105/105 [==============================] - 0s 125us/sample - loss: 0.7559 - val_loss: 0.9100\n",
      "Epoch 272/300\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 0.7570 - val_loss: 0.9059\n",
      "Epoch 273/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7560 - val_loss: 0.9046\n",
      "Epoch 274/300\n",
      "105/105 [==============================] - 0s 131us/sample - loss: 0.7562 - val_loss: 0.9029\n",
      "Epoch 275/300\n",
      "105/105 [==============================] - 0s 128us/sample - loss: 0.7557 - val_loss: 0.9031\n",
      "Epoch 276/300\n",
      "105/105 [==============================] - 0s 120us/sample - loss: 0.7573 - val_loss: 0.9051\n",
      "Epoch 277/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7561 - val_loss: 0.9047\n",
      "Epoch 278/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7563 - val_loss: 0.8998\n",
      "Epoch 279/300\n",
      "105/105 [==============================] - 0s 112us/sample - loss: 0.7568 - val_loss: 0.9017\n",
      "Epoch 280/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7562 - val_loss: 0.8998\n",
      "Epoch 281/300\n",
      "105/105 [==============================] - 0s 117us/sample - loss: 0.7580 - val_loss: 0.9028\n",
      "Epoch 282/300\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.7573 - val_loss: 0.9031\n",
      "Epoch 283/300\n",
      "105/105 [==============================] - 0s 110us/sample - loss: 0.7576 - val_loss: 0.9023\n",
      "Epoch 284/300\n",
      "105/105 [==============================] - 0s 103us/sample - loss: 0.7569 - val_loss: 0.9042\n",
      "Epoch 285/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7573 - val_loss: 0.9037\n",
      "Epoch 286/300\n",
      "105/105 [==============================] - 0s 121us/sample - loss: 0.7559 - val_loss: 0.9056\n",
      "Epoch 287/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7560 - val_loss: 0.9039\n",
      "Epoch 288/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7568 - val_loss: 0.9032\n",
      "Epoch 289/300\n",
      "105/105 [==============================] - 0s 108us/sample - loss: 0.7560 - val_loss: 0.9012\n",
      "Epoch 290/300\n",
      "105/105 [==============================] - 0s 123us/sample - loss: 0.7567 - val_loss: 0.9027\n",
      "Epoch 291/300\n",
      "105/105 [==============================] - 0s 127us/sample - loss: 0.7567 - val_loss: 0.9021\n",
      "Epoch 292/300\n",
      "105/105 [==============================] - 0s 114us/sample - loss: 0.7564 - val_loss: 0.9063\n",
      "Epoch 293/300\n",
      "105/105 [==============================] - 0s 97us/sample - loss: 0.7561 - val_loss: 0.9090\n",
      "Epoch 294/300\n",
      "105/105 [==============================] - 0s 132us/sample - loss: 0.7569 - val_loss: 0.9123\n",
      "Epoch 295/300\n",
      "105/105 [==============================] - 0s 116us/sample - loss: 0.7567 - val_loss: 0.9112\n",
      "Epoch 296/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.7568 - val_loss: 0.9118\n",
      "Epoch 297/300\n",
      "105/105 [==============================] - 0s 109us/sample - loss: 0.7572 - val_loss: 0.9158\n",
      "Epoch 298/300\n",
      "105/105 [==============================] - 0s 118us/sample - loss: 0.7579 - val_loss: 0.9128\n",
      "Epoch 299/300\n",
      "105/105 [==============================] - 0s 119us/sample - loss: 0.7564 - val_loss: 0.9101\n",
      "Epoch 300/300\n",
      "105/105 [==============================] - 0s 104us/sample - loss: 0.7584 - val_loss: 0.9115\n"
     ]
    }
   ],
   "source": [
    "callback_list = [tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=300, \n",
    "                    callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep learning",
   "language": "python",
   "name": "dl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
